- Other books that provide treatments of state space models and techniques include Harvey (1989), West and Harrison (1997), Kitagawa and Gersch (1996) and Kim and Nelson (1999). More general books on time series analysis with substantial treatments of state space methods are, for example, Brockwell and Davis (1987), Hamilton (1994) and Shumway and Stoffer (2000).


The integration of Bayesian update mechanisms into recursive Expectation-Maximization (EM) algorithms represents a significant advancement in the estimation of variance in state space models. This method leverages the inverse gamma prior, renowned for its conjugacy with the normal distribution, particularly in the context of variance parameters. The inverse gamma prior, denoted as $\text{IGamma}(\alpha, \beta)$, where $\alpha$ and $\beta$ are the shape and scale parameters respectively, is instrumental in updating the variance estimates in a Bayesian framework. Its conjugate nature simplifies the posterior update steps, allowing for analytical solutions.

Specifically, given a prior $\text{IGamma}(\alpha, \beta)$, the posterior distribution after observing data $X$ with likelihood assuming a normal distribution with variance $\sigma^2$, updates to $\text{IGamma}(\alpha + \frac{n}{2}, \beta + \frac{1}{2}\sum_{i=1}^{n}(x_i - \mu)^2)$, where $n$ is the number of observations, and $\mu$ is the mean. This recursive update mechanism within the EM algorithm facilitates a more nuanced and dynamically adjusting approach to variance estimation in state space models, offering enhanced accuracy and efficiency in parameter estimation. By iteratively adjusting the prior in light of new observations, the Bayesian update within a recursive EM framework embodies a powerful method for coping with complex stochastic processes.